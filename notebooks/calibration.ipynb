{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put `coveval` folder into the path and import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coveval import utils\n",
    "from coveval import scoring\n",
    "from coveval.connectors import covasim\n",
    "from coveval.connectors import covidsim\n",
    "from coveval.connectors import generic\n",
    "from coveval.connectors import mc19\n",
    "from coveval.core import smoothing\n",
    "from coveval.core import normalising\n",
    "from coveval.core import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convenient utility to update the notebook when simultaneously working on the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reimport():\n",
    "    importlib.reload(mc19)\n",
    "    importlib.reload(covasim)\n",
    "    importlib.reload(generic)\n",
    "    importlib.reload(covidsim)\n",
    "    importlib.reload(utils)\n",
    "    importlib.reload(normalising)\n",
    "    importlib.reload(losses)\n",
    "    importlib.reload(smoothing)\n",
    "    importlib.reload(scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reimport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- running all the cells in this notebook should allow you to reproduce the images in [./figs/](./figs/).\n",
    "- we might talk about \"Imperial\" and \"covidsim\" interchangeably.\n",
    "- we might use score and loss interchangeably: our score is a loss, so the lower the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve reported data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrieve the latest data reported for the USA on https://covidtracking.com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reported_usa = utils.get_outbreak_data_usa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at number of reported daily fatalities (field `deathIncrease`) for each state of interest and experiment we different smoothing procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state_reported_data(state, reported, smoothers, t_min='2020-03'):\n",
    "    df = reported.loc[state].copy()\n",
    "    for s_name, s in smoothers.items():\n",
    "        s.smooth_df(df, 'deathIncrease', inplace=True)\n",
    "        df.rename(columns={'deathIncrease_smoothed': 'deathIncrease_smoothed_' + s_name}, inplace=True)\n",
    "        \n",
    "    utils.show_data(df, cols=['deathIncrease_smoothed_missed','deathIncrease_smoothed_gaussian'],\n",
    "                scatter=['deathIncrease'], t_min=t_min, y_label='daily fatalities', figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_smoothers = {'missed': smoothing.missed_cases(), 'gaussian': smoothing.gaussian(3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the smoother for each geo in this dict\n",
    "smoother = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-CA', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['California'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illinois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-IL', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['Illinois'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-MA', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['Massachusetts'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-MI', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['Michigan'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New_Jersey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-NJ', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['New_Jersey'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example of issues with the data reported that could be addressed by implementing a more robust filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reported_usa.loc['US-NJ'].copy()\n",
    "y = df['deathIncrease'].values\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(np.arange(len(y)),y, alpha=0.3, label='reported')\n",
    "plt.plot(np.arange(len(y)),scipy.ndimage.gaussian_filter1d(y, sigma=3), c='r', label='gaussian filter')\n",
    "plt.plot(np.arange(len(y)),scipy.ndimage.gaussian_filter1d(scipy.ndimage.median_filter(y, size=3), sigma=3), c='g', label='gaussian + median filter')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity's sake we'll stick to the same Gaussian filter for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New_York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state_reported_data('US-NY', reported_usa, example_smoothers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoother['New_York'] = example_smoothers['gaussian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another case where a fancier filter could help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reported_usa.loc['US-NY'].copy()\n",
    "y = df['deathIncrease'].values\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(np.arange(len(y)),y, alpha=0.3, label='reported')\n",
    "plt.plot(np.arange(len(y)),scipy.ndimage.gaussian_filter1d(y, sigma=3), c='r', label='gaussian filter')\n",
    "plt.plot(np.arange(len(y)),scipy.ndimage.gaussian_filter1d(scipy.ndimage.median_filter(y, size=3), sigma=3), c='g', label='gaussian + median filter')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_iso = {\n",
    "    'California': 'US-CA',\n",
    "    'Illinois': 'US-IL',\n",
    "    'Massachusetts': 'US-MA',\n",
    "    'Michigan': 'US-MI',\n",
    "    'New_Jersey': 'US-NJ',\n",
    "    'New_York': 'US-NY',\n",
    "    'Pennsylvania': 'US-PA'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And corresponding interventions times, valid as of beginning of June 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions = {\n",
    "    'California': ['2020-03-19','2020-03-31'],\n",
    "    'Illinois': ['2020-03-17','2020-03-21'],\n",
    "    'Massachusetts': ['2020-03-17','2020-03-24'],\n",
    "    'Michigan': ['2020-03-16','2020-03-24','2020-06-01'],\n",
    "    'New_Jersey': ['2020-03-18','2020-03-21','2020-05-13'],\n",
    "    'New_York': ['2020-03-18','2020-03-22','2020-05-22'],\n",
    "    'Pennsylvania': ['2020-03-16','2020-04-01']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details on the Imperial data see this [README](../data/2020_04_30/covidsim/README.md) on how it was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load calibration runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some utilities functions to extract the contact reduction value CR from the folder name and build a unique id based on the R0 and CR values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cr(name, regex=r\"_cr([\\d]+).txt\"):\n",
    "    cr_regex = regex\n",
    "    out = re.findall(cr_regex, name)\n",
    "    if len(out) > 1:\n",
    "        raise ValueError('Expected exactly 1 match, found more.')\n",
    "    elif len(out) == 0:\n",
    "        print(name)\n",
    "        raise ValueError('Expected exactly 1 match, found none.')\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_to_id(r0, cr):\n",
    "    return 'R' + str(r0) + '_cr' + str(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_folder = {'2020-04-30': '../data/2020_04_30/covidsim',\n",
    "                   '2020-05-30': '../data/2020_05_30/covidsim'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load predictions for daily fatalities (`incDeath`) for each run in the grid, and organise them by unique parameters id (this can take a few minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_raw = {}\n",
    "imperial_runs = {}\n",
    "imperial_params = {}\n",
    "for cal in imperial_folder.keys():\n",
    "    # load raw dict\n",
    "    imperial_raw[cal] = covidsim.batch_load_predictions(imperial_folder[cal], cols=['incDeath'],\n",
    "                                                        prefix='imperial_',\n",
    "                                                        exclude=['_config_files', '_param_files'])\n",
    "\n",
    "    # organise by ids and store params\n",
    "    imperial_params[cal] = {}\n",
    "    imperial_runs[cal] = {}\n",
    "    for geo in imperial_raw[cal].keys():\n",
    "        imperial_params[cal][geo] = {}\n",
    "        imperial_runs[cal][geo] = {}\n",
    "        for r0 in imperial_raw[cal][geo].keys():\n",
    "            for param in imperial_raw[cal][geo][r0].keys():\n",
    "                cr = extract_cr(param)\n",
    "                imperial_params[cal][geo][param_to_id(r0, cr)] = {'r0': float(r0), 'cr': float(cr)}\n",
    "                imperial_runs[cal][geo][param_to_id(r0, cr)] = imperial_raw[cal][geo][r0][param]\n",
    "del imperial_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute quantiles to summarise variations of predictions amongst repeats runs for a given (R0, CR) set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_aggregated = {}\n",
    "for cal in imperial_folder.keys():\n",
    "    imperial_aggregated[cal] = {}\n",
    "    for geo in imperial_runs[cal].keys():\n",
    "        imperial_aggregated[cal][geo] = {}\n",
    "        for _id in imperial_runs[cal][geo].keys():\n",
    "            imperial_aggregated[cal][geo][_id] = utils.calc_quantiles_over_dfs(dfs=imperial_runs[cal][geo][_id],\n",
    "                                                                               col='imperial_incDeath',\n",
    "                                                                               q=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the reported values `deathIncrease`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cal in imperial_folder.keys():\n",
    "    for geo in imperial_aggregated[cal].keys():\n",
    "        reported_usa_geo = reported_usa.loc[(usa_iso[geo], 'deathIncrease')]\n",
    "        for _id, df in imperial_aggregated[cal][geo].items():\n",
    "            imperial_aggregated[cal][geo][_id] = utils.add_outbreak_data(df, reported_usa_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Gaussian filter to smooth out `covidsim` predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_pred_smoother = smoothing.gaussian(3)\n",
    "cols = ['imperial_incDeath-0.1','imperial_incDeath-0.5','imperial_incDeath-0.9']\n",
    "for cal in imperial_folder.keys():\n",
    "    print(cal)\n",
    "    for geo in imperial_aggregated[cal].keys():\n",
    "        print('  ' + geo + '...')\n",
    "        for _id, df in imperial_aggregated[cal][geo].items():\n",
    "            for col in cols:\n",
    "                imperial_pred_smoother.smooth_df(df, col, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the data (we pick an arbitrary state and set of parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = '2020-04-30'\n",
    "geo = 'California'\n",
    "utils.show_data(df= imperial_aggregated[cal][geo]['R2.2_cr90'],\n",
    "                cols=['imperial_incDeath-0.5','imperial_incDeath-0.5_smoothed'], \n",
    "                scatter=['deathIncrease'],\n",
    "                t_min='2020-03-03', t_max='2020-07-01',\n",
    "                fill_between=[['imperial_incDeath-0.1_smoothed','imperial_incDeath-0.9_smoothed']],\n",
    "                colors={'fill_between': ['r'],\n",
    "                        'cols': {'imperial_incDeath-0.5_smoothed': 'r', 'imperial_incDeath-0.5': 'b'},\n",
    "                        'scatter': {'deathIncrease': '#797979'}},\n",
    "                title=cal,\n",
    "                title_font={'fontsize': 16}, figsize=(12,5),\n",
    "                show_times=[cal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = '2020-05-30'\n",
    "geo = 'California'\n",
    "utils.show_data(df=imperial_aggregated[cal][geo]['R2.2_cr90'],\n",
    "                cols=['imperial_incDeath-0.5','imperial_incDeath-0.5_smoothed'], \n",
    "                scatter=['deathIncrease'],\n",
    "                t_min='2020-03-03', t_max='2020-07-01',\n",
    "                fill_between=[['imperial_incDeath-0.1_smoothed','imperial_incDeath-0.9_smoothed']],\n",
    "                colors={'fill_between': ['r'],\n",
    "                        'cols': {'imperial_incDeath-0.5_smoothed': 'r', 'imperial_incDeath-0.5': 'b'},\n",
    "                        'scatter': {'deathIncrease': '#797979'}},\n",
    "                title=cal,\n",
    "                title_font={'fontsize': 16}, figsize=(12,5),\n",
    "                show_times=[cal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define scorers for each geo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = {geo: scoring.scorer(smoother=smoother[geo],\n",
    "                               normaliser=normalising.dynamic_scaling(weights=[1, 2, 3, 4, 5, 6, 7]),\n",
    "                               loss=losses.poisson()) for geo in smoother.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of parameters, compute score of the _median_ prediction up to the calibration date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_results = {}\n",
    "imperial_scores = {}\n",
    "for cal in imperial_aggregated.keys():\n",
    "    print(cal)\n",
    "    imperial_results[cal] = {}\n",
    "    imperial_scores[cal] = {}\n",
    "    for geo in sorted(imperial_aggregated[cal].keys()):\n",
    "        print('  ' + geo + '...')\n",
    "        imperial_results[cal][geo] = {}\n",
    "        imperial_scores[cal][geo] = {}\n",
    "        for _id, df in imperial_aggregated[cal][geo].items():\n",
    "            # get detail scoring results up to calibration data\n",
    "            imperial_results[cal][geo][_id] = scorers[geo].score_df(df=df,\n",
    "                                                                    col_truth='deathIncrease',\n",
    "                                                                    col_pred='imperial_incDeath-0.5_smoothed',\n",
    "                                                                    t_max=cal,\n",
    "                                                                    inplace=True)\n",
    "            # store score\n",
    "            imperial_scores[cal][geo][_id] = round(imperial_results[cal][geo][_id]['score'], 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly check that only the relevant periods were taken into account for each calibration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_results['2020-04-30']['New_York']['R3.75_cr80']['idx'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_results['2020-05-30']['New_York']['R3.75_cr80']['idx'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify parameters with best scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort scores for a given geo to identify which set of `(R0,CR)` in the grid compared most favourably to the reported data. The below produces a list of tuples `('params_id', 'score')` sorted by ascending `score` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_scores_sorted = {}\n",
    "for cal in imperial_aggregated.keys():\n",
    "    imperial_scores_sorted[cal] = {}\n",
    "    for geo in imperial_aggregated[cal].keys():\n",
    "        imperial_scores_sorted[cal][geo] = sorted(imperial_scores[cal][geo].items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the average R0 and contact reduction parameters for the top n scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_average_imperial_params(cal, n, precision=2):\n",
    "    scores = imperial_scores_sorted[cal]\n",
    "    out = {}\n",
    "    for geo in scores.keys():\n",
    "        _r0s = []\n",
    "        _crs = []\n",
    "        for e in scores[geo][:n]:\n",
    "            p = imperial_params[cal][geo][e[0]]\n",
    "            _r0s.append(p['r0'])\n",
    "            _crs.append(p['cr'])\n",
    "        out[geo] = {'r0': (round(np.mean(_r0s), precision), round(np.std(_r0s), precision)),\n",
    "                    'cr': (round(np.mean(_crs), precision), round(np.std(_crs), precision))}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see compute what the best, and average top-3, such values were for the models calibrated on data up to `2020-04-30`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_average_imperial_params('2020-04-30', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_average_imperial_params('2020-04-30', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see compute what the best, and average top-3, such values were for the models calibrated a month later, i.e. with data up to `2020-05-30` available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_average_imperial_params('2020-05-30', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_average_imperial_params('2020-05-30', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight best scoring predictions in grid of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_imperial_grid(params, geo):\n",
    "    r_values = set()\n",
    "    cr_values = set()\n",
    "    for v in params[geo].values():\n",
    "        r_values.add(v['r0'])\n",
    "        cr_values.add(v['cr'])\n",
    "    \n",
    "    out_headers = {'rows': ['R=' + str(r) for r in sorted(r_values)],\n",
    "                   'cols': ['SD=' + str(int(cr)) + '%' for cr in sorted(cr_values)]}\n",
    "    out = np.asarray([[param_to_id(r, int(cr)) for cr in sorted(cr_values)] for r in sorted(r_values)])        \n",
    "    return out, out_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imperial_grid(cal, geo, t_max='2020-07-01'):\n",
    "    _params, _headers = build_imperial_grid(imperial_params[cal], geo) \n",
    "    utils.batch_show_data(geo=geo,\n",
    "                          params=_params,\n",
    "                          data = imperial_aggregated[cal],\n",
    "                          scores=imperial_scores[cal],\n",
    "                          cols=['imperial_incDeath-0.5_smoothed','deathIncrease_smoothed'],\n",
    "                          fill_between=[('imperial_incDeath-0.1_smoothed', 'imperial_incDeath-0.9_smoothed')],\n",
    "                          scatter=['deathIncrease'],\n",
    "                          colors={'fill_between': ['#FFB479'],\n",
    "                                  'scatter': {'deathIncrease': '#85C5FF'},\n",
    "                                  'cols': {'imperial_incDeath-0.5_smoothed': '#FFB479',\n",
    "                                           'deathIncrease_smoothed': '#85C5FF'}},\n",
    "                          highlight = 'min',\n",
    "                          highlight_num=3,\n",
    "                          figsize=1.1,\n",
    "                          t_max=t_max,\n",
    "                          show_times=interventions[geo] + [cal.replace('_','-')],\n",
    "                          headers=_headers,\n",
    "                          linewidths={cal: 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to sanity check the above let's visualise the predictions for each set of parameters and see whether the top-n pics according to our score look reasonable. Each row correspond to a given R0 value, and each column to the effectiveness of the social distancing (SD) measures in reducing the contact rates (i.e. if SD=25% this corresponds to contact rates of 0.75 compared to no social distancing).\n",
    "- blue dots and lines: raw and smoothed truth respectively\n",
    "- red line and shaded area: median prediction of `covidsim` model and 10-90% quantile range respectively\n",
    "- thin vertical lines: interventions in the state\n",
    "- thick vertical line: calibration date (i.e. the model had acess to data to the left of that line)\n",
    "- the score of each model is in the title (remember our score is a loss, so the lower the better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the commands below for each state should reproduce the figures in [./figs/covidsim_grid/](./figs/covidsim_grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_imperial_grid('2020-04-30', 'California')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_imperial_grid('2020-05-30', 'New_York')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covasim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details on the Covasim data see this [README](../data/2020_04_30/covasim/README.md) on how it was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all calibration runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load predictions for daily fatalities (`new_deaths`) for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_folder = {'2020-04-30': '../data/2020_04_30/covasim/',\n",
    "                  '2020-05-30': '../data/2020_05_30/covasim/',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_raw = {}\n",
    "covasim_calibrations_params = {}\n",
    "covasim_calibrations_sorted = {}\n",
    "for cal in covasim_folder.keys():\n",
    "    # load raw predictions\n",
    "    covasim_raw[cal] = covasim.batch_load_predictions(covasim_folder[cal], filename='results.json', prefix='covasim_', cols=['new_deaths'])\n",
    "\n",
    "    # load parameters and loss associated to each calibration\n",
    "    covasim_calibrations_params[cal] = {}\n",
    "    for geo in covasim_raw[cal].keys():\n",
    "        covasim_calibrations_params[cal][geo] = {}\n",
    "        for n_trials in covasim_raw[cal][geo].keys():\n",
    "            covasim_calibrations_params[cal][geo][n_trials] = {}\n",
    "            for n in covasim_raw[cal][geo][n_trials].keys():\n",
    "                covasim_calibrations_params[cal][geo][n_trials][n] = {}\n",
    "                with open(os.path.join(covasim_folder[cal], geo, n_trials, n, 'loss.json')) as f:\n",
    "                    covasim_calibrations_params[cal][geo][n_trials][n].update(json.load(f))\n",
    "                with open(os.path.join(covasim_folder[cal], geo, n_trials, n, 'calibrated_parameters.json')) as f:\n",
    "                    covasim_calibrations_params[cal][geo][n_trials][n].update(json.load(f))\n",
    "\n",
    "    # sort each calibration for a geo based on its mismatch\n",
    "    covasim_calibrations_sorted[cal] = {}\n",
    "    for geo in covasim_raw[cal].keys():\n",
    "        covasim_calibrations_sorted[cal][geo] = {}\n",
    "        for n_trials in covasim_raw[cal][geo].keys():\n",
    "            covasim_calibrations_sorted[cal][geo][n_trials] = sorted(covasim_calibrations_params[cal][geo][n_trials].items(), key=lambda x: x[1]['mismatch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute mean prediction within calibration replicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the mean of predictions made with the same parameters (one calibration = one set of parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_calibrations_mean = {}\n",
    "for cal in covasim_raw.keys():\n",
    "    covasim_calibrations_mean[cal] = {}\n",
    "    for geo in covasim_raw[cal].keys():\n",
    "        covasim_calibrations_mean[cal][geo] = {}\n",
    "        for n_trials in covasim_raw[cal][geo].keys():\n",
    "            covasim_calibrations_mean[cal][geo][n_trials] = {}\n",
    "            for n in covasim_raw[cal][geo][n_trials].keys():\n",
    "                dfs = covasim_raw[cal][geo][n_trials][n].values()\n",
    "                covasim_calibrations_mean[cal][geo][n_trials][n] = utils.calc_mean_over_dfs(dfs, 'covasim_new_deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute inter-calibration quantiles for mean prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If different calibrations have been performed, i.e. if different set of parameters were available, we compute inter-calibration quantiles, keeping only the `covasim_n_best` calibrations (as measured by the loss associated to each calibration):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_n_best = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_aggregated = {}\n",
    "for cal in covasim_raw.keys():\n",
    "    covasim_aggregated[cal] = {}\n",
    "    for geo in covasim_raw[cal].keys():\n",
    "        covasim_aggregated[cal][geo] = {}\n",
    "        for n_trials in covasim_raw[cal][geo].keys():\n",
    "            dfs = {}\n",
    "            for e in covasim_calibrations_sorted[cal][geo][n_trials][:covasim_n_best]:\n",
    "                n = e[0]\n",
    "                dfs[n] = covasim_calibrations_mean[cal][geo][n_trials][n]\n",
    "            covasim_aggregated[cal][geo][n_trials] = utils.calc_quantiles_over_dfs(dfs, col='covasim_new_deaths-mean', q=[0.2, 0.5, 0.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the reported values `deathIncrease`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cal in covasim_aggregated.keys():\n",
    "    for geo in covasim_aggregated[cal].keys():\n",
    "        reported_usa_geo = reported_usa.loc[(usa_iso[geo], 'deathIncrease')]\n",
    "        for _id, df in covasim_aggregated[cal][geo].items():\n",
    "            covasim_aggregated[cal][geo][_id] = utils.add_outbreak_data(df, reported_usa_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Gaussian filter (same as for `covidsim`) to smooth out covasim predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covasim_pred_smoother = smoothing.gaussian(3)\n",
    "cols = ['covasim_new_deaths-mean-0.2','covasim_new_deaths-mean-0.5','covasim_new_deaths-mean-0.8']\n",
    "for cal in covasim_aggregated.keys():\n",
    "    for geo in covasim_aggregated[cal].keys():\n",
    "        for _id, df in covasim_aggregated[cal][geo].items():\n",
    "            for col in cols:\n",
    "                covasim_pred_smoother.smooth_df(df, col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the data (again, we pick an arbitrary state and set of parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = '2020-04-30'\n",
    "geo = 'New_York'\n",
    "utils.show_data(covasim_aggregated[cal][geo]['500'],\n",
    "                cols=['covasim_new_deaths-mean-0.5','covasim_new_deaths-mean-0.5_smoothed'], \n",
    "                scatter=['deathIncrease'],\n",
    "                t_min='2020-03-03', t_max='2020-07-01',\n",
    "                fill_between=[['covasim_new_deaths-mean-0.2_smoothed','covasim_new_deaths-mean-0.8_smoothed']],\n",
    "                colors={'fill_between': ['#B4A9FF'],\n",
    "                        'cols': {'covasim_new_deaths-mean-0.5': '#FFACF1',\n",
    "                                 'covasim_new_deaths-mean-0.5_smoothed': '#B483FF'},\n",
    "                        'scatter': {'deathIncrease': '#797979'}},\n",
    "                title=cal,\n",
    "                title_font={'fontsize': 16}, figsize=(12,5),\n",
    "                show_times=[cal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = '2020-05-30'\n",
    "geo = 'New_York'\n",
    "utils.show_data(covasim_aggregated[cal][geo]['500'],\n",
    "                cols=['covasim_new_deaths-mean-0.5','covasim_new_deaths-mean-0.5_smoothed'], \n",
    "                scatter=['deathIncrease'],\n",
    "                t_min='2020-03-03', t_max='2020-07-01',\n",
    "                fill_between=[['covasim_new_deaths-mean-0.2_smoothed','covasim_new_deaths-mean-0.8_smoothed']],\n",
    "                colors={'fill_between': ['#B4A9FF'],\n",
    "                        'cols': {'covasim_new_deaths-mean-0.5': '#FFACF1',\n",
    "                                 'covasim_new_deaths-mean-0.5_smoothed': '#B483FF'},\n",
    "                        'scatter': {'deathIncrease': '#797979'}},\n",
    "                title=cal,\n",
    "                title_font={'fontsize': 16}, figsize=(12,5),\n",
    "                show_times=[cal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details on the MC-19 data see this [README](../data/2020_06_11/mc19/README.md). In particular note that, unlike for `covidsim` and `covasim`, in this case the calibration was performed internally by the model using the latest available data at the time (`2020-06-11`). We compare these predictions to those made by covadsim and covasim when calibrated with data up to `2020-05-30`: this is not entirely fair (as it gives MC-19 about 10 days more of historical data) but good enough for our purpose here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load predictions for the daily number of fatalities (`dailyDeath`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mc19_folder = '../data/2020_06_11/mc19/'\n",
    "mc19_predictions = mc19.batch_load_predictions(mc19_folder, filename='*.json', prefix='mc19_', exclude=['_queries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the reported values `deathIncrease`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for geo, df in mc19_predictions.items():\n",
    "    reported_usa_geo = reported_usa.loc[(usa_iso[geo], 'deathIncrease')]\n",
    "    mc19_predictions[geo] = utils.add_outbreak_data(df, reported_usa_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = 'New_York'\n",
    "utils.show_data(mc19_predictions[geo], \n",
    "                cols=['mc19_dailyDeath-percentile50'], \n",
    "                scatter=['deathIncrease'],\n",
    "                fill_between=[('mc19_dailyDeath-percentile10','mc19_dailyDeath-percentile90'),\n",
    "                              ('mc19_dailyDeath-percentile20','mc19_dailyDeath-percentile80')],\n",
    "                t_min='2020-03-03', t_max='2020-07-01',\n",
    "                colors={'cols': {'mc19_dailyDeath-percentile50': 'g'},\n",
    "                        'scatter': {'deathIncrease': '#797979'},\n",
    "                        'fill_between': ['#8AC277','#8AC277']},\n",
    "                show_times=['2020-06-11'],\n",
    "                title='2020-06-11',\n",
    "                title_font={'fontsize': 16}, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we use the terms `covidsim` and `Imperial` interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add predictions to Imperial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add `covasim` and `MC-19` predictions to the dataframes containing those of `covidsim`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_imperial_predictions(dfs, to_add, cols=None):\n",
    "    '''\n",
    "    dfs : a dictionary {'param': DataFrame} corresponding to the calibration grid for Imperial\n",
    "    to_add : a sequence of DataFrame to merge to each value of dfs.\n",
    "    cols : [str] which columns of the values of dfs to keep.\n",
    "    '''\n",
    "    out = {}\n",
    "    for _id, df in dfs.items():\n",
    "        out[_id] = df\n",
    "        if cols is not None:\n",
    "            out[_id] = out[_id][cols]\n",
    "        for df_to_add in to_add:\n",
    "            out[_id] = out[_id].merge(df_to_add, left_index=True, right_index=True, how='outer')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comparison = {}\n",
    "for cal in ['2020-04-30','2020-05-30']:\n",
    "    data_comparison[cal] = {}\n",
    "    _imperial_cols = ['imperial_incDeath-0.1_smoothed', 'imperial_incDeath-0.5_smoothed',\n",
    "                      'imperial_incDeath-0.9_smoothed', 'deathIncrease','deathIncrease_smoothed']\n",
    "    _covasim_cols = ['covasim_new_deaths-mean-0.2_smoothed','covasim_new_deaths-mean-0.5_smoothed',\n",
    "                     'covasim_new_deaths-mean-0.8_smoothed']\n",
    "    _mc19_cols = ['mc19_dailyDeath-percentile10','mc19_dailyDeath-percentile20','mc19_dailyDeath-percentile50',\n",
    "                  'mc19_dailyDeath-percentile80','mc19_dailyDeath-percentile90']\n",
    "    for geo in imperial_aggregated[cal].keys():\n",
    "        n_trials = '500'\n",
    "        data_comparison[cal][geo] = add_to_imperial_predictions(dfs=imperial_aggregated[cal][geo],\n",
    "                                                                to_add=[covasim_aggregated[cal][geo][n_trials][_covasim_cols],\n",
    "                                                                        mc19_predictions[geo][_mc19_cols]],\n",
    "                                                                cols=_imperial_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with best Imperial prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise other models predictions against a specified `covidsim` prediction (the one with the best score by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comparison_imperial(df, idm=True, mc19=False, hide_fb=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot different models predictions on the same graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        A DataFrame with a DatetimeIndex containing the data to plot. Should contain the columns\n",
    "        ['imperial_incDeath-0.5_smoothed','deathIncrease_smoothed'] and if `hide_fb` is set to False also the\n",
    "        columns ['imperial_incDeath-0.1_smoothed','imperial_incDeath-0.9_smoothed'].\n",
    "    idm : boolean, optional\n",
    "        If True show IDM data i.e. column 'covasim_new_deaths-mean-0.5_smoothed' and, if relevant, the columns\n",
    "        ['covasim_new_deaths-mean-0.2_smoothed','covasim_new_deaths-mean-0.8_smoothed'].\n",
    "    mc19 : boolean, optional\n",
    "        If True show MC-19 data i.e. column 'mc19_dailyDeath-percentile50' and, if relevant, the columns\n",
    "        ['mc19_dailyDeath-percentile10','mc19_dailyDeath-percentile90'].\n",
    "    hide_fb : boolean, optional\n",
    "        If True only show the median lines for each model.\n",
    "    figsize : 2-tuple, optional\n",
    "        The figure size.\n",
    "    **kwargs : keyword arguments of `coveval.utils.show_data()`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A matplotlib.axes object.\n",
    "    \"\"\"\n",
    "    # specify columns to display\n",
    "    scatter=['deathIncrease']\n",
    "    cols=['imperial_incDeath-0.5_smoothed','deathIncrease_smoothed']\n",
    "    fill_between=[('imperial_incDeath-0.1_smoothed','imperial_incDeath-0.9_smoothed')]\n",
    "    if idm:\n",
    "        cols.append('covasim_new_deaths-mean-0.5_smoothed')\n",
    "        fill_between.append(('covasim_new_deaths-mean-0.2_smoothed','covasim_new_deaths-mean-0.8_smoothed'))\n",
    "    if mc19:\n",
    "        cols.append('mc19_dailyDeath-percentile50')\n",
    "        fill_between.append(('mc19_dailyDeath-percentile10','mc19_dailyDeath-percentile90'))\n",
    "    if hide_fb:\n",
    "        fill_between=None\n",
    "        \n",
    "    return utils.show_data(df=df, cols=cols, fill_between=fill_between, scatter=scatter,\n",
    "                           y_label='daily fatalities', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_show_comparison_best_imperial(cal, imperial_id=None, geos=None, n_cols=3, n_rows=None, leg_pos=-1,\n",
    "                                        figsize=1.25, idm=True, mc19=False, t_min='2020-03', t_max=None,\n",
    "                                        **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper around `show_comparison_imperial()` that plots a grid comparing predictions by Imperial model and\n",
    "    others for different geographies.\n",
    "    \n",
    "    Relies on the existence of the `data_comparison`, `imperial_scores_sorted` and `interventions`\n",
    "    dictionaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cal : str\n",
    "        Date of calibration that is the key to a {cal: {geo: {id: df}}} dictionary where id corresponds to the\n",
    "        Imperial parameters id and df is a DataFrame with a DatetimeIndex containing the data to plot.\n",
    "    imperial_id : str, optional\n",
    "        If specified use this value for `id` in the dictionary mentioned above. If unspecified, \n",
    "    geos : [str], optional\n",
    "        If specified only plot data for these geos.\n",
    "    n_cols : int, optional\n",
    "        Number of columns.\n",
    "    n_rows : int, optional\n",
    "        Number of rows. If unspecified, determined based on `n_cols` and `geos`.\n",
    "    leg_pos : int, optional\n",
    "        Index of plot under which to positional the legend, using the flattened grid representation.\n",
    "    figsize : 2-tuple or float, optional\n",
    "        If a tuple specifies directly the figure size. If a float scales the default figure size.\n",
    "        If unspecified the figure size is determined automatically based on the number of rows and columns.\n",
    "    **kwargs : keyword arguments of `show_comparison_imperial`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A matplotlib.axes object.\n",
    "    \"\"\"\n",
    "    # determine grid size\n",
    "    if geos is None:\n",
    "        geos = data_comparison[cal].keys() \n",
    "    if n_rows is None:\n",
    "        n_rows = len(geos) // n_cols\n",
    "        if len(geos) % n_cols != 0:\n",
    "            n_rows += 1        \n",
    "    if len(geos) > n_rows * n_cols:\n",
    "        raise ValueError('too many geos to plot for the grid.')\n",
    "        \n",
    "    # determine figure size\n",
    "    if figsize is None:\n",
    "        figsize = 1\n",
    "    if type(figsize) in [int, float]:\n",
    "        figsize = (8 * n_cols * figsize, 4 * n_rows*figsize)    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "        \n",
    "    # plot each geo\n",
    "    for i, geo in enumerate(sorted(geos)):\n",
    "        if imperial_id is None:\n",
    "            _id = imperial_scores_sorted[cal][geo][0][0]\n",
    "        # manual adjustment to scale in NJ to minimise impact due a mistake in the reported data\n",
    "        y_max = 750 if geo == 'New_Jersey' else None\n",
    "        lines = show_comparison_imperial(df=data_comparison[cal][geo][_id],\n",
    "                                         idm=idm,\n",
    "                                         mc19=mc19,\n",
    "                                         t_min=t_min,\n",
    "                                         t_max=t_max,\n",
    "                                         colors={'fill_between': ['r','#B4A9FF','#8AC277'],\n",
    "                                                 'cols': {'imperial_incDeath-0.5_smoothed':'r',\n",
    "                                                          'covasim_new_deaths-mean-0.5_smoothed': '#942192',\n",
    "                                                          'mc19_dailyDeath-percentile50': 'g',\n",
    "                                                          'deathIncrease_smoothed': '#797979'},\n",
    "                                                 'scatter': {'deathIncrease': '#797979'}},\n",
    "                                         ax=axes.flatten()[i],\n",
    "                                         title=geo,\n",
    "                                         title_font={'fontsize': 16, 'fontweight': 'normal'},\n",
    "                                         show_leg=False,\n",
    "                                         linewidths={cal: 3},\n",
    "                                         show_times=interventions[geo] + [cal],\n",
    "                                         y_max=y_max,\n",
    "                                         **kwargs)\n",
    "    fig.suptitle(cal, fontsize=22)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    # add legend\n",
    "    labels = {'imperial_incDeath-0.5_smoothed': 'covidsim (Imperial)',\n",
    "              'covasim_new_deaths-mean-0.5_smoothed': 'covasim (IDM)',\n",
    "              'mc19_dailyDeath-percentile50': 'MC-19',\n",
    "              'deathIncrease_smoothed': 'reported (smoothed)',\n",
    "              'deathIncrease': 'reported'}\n",
    "    _h = []\n",
    "    _l = []\n",
    "    for label, line in sorted(lines.items(), key=lambda x: x[0]):\n",
    "        _h.append(line)\n",
    "        _l.append(labels[label])\n",
    "    axes.flatten()[leg_pos].legend(handles=_h, labels=_l,loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "                                   fontsize='x-large', ncol=len(lines.keys()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the commands below with `t_max='2020-07-13'` should reproduce the figures [./figs/2020-04-30_models.png](./figs/2020-04-30_models.png) and [./figs/2020-05-30_models.png](./figs/2020-05-30_models.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_show_comparison_best_imperial('2020-04-30', t_max='2020-07-13', leg_pos=-2, figsize=1.25, mc19=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_show_comparison_best_imperial('2020-05-30', t_max='2020-07-13', leg_pos=-2, figsize=1.25, mc19=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models performance w.r.t to truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess how each model predictions compare to the truth, using 2 summary metrics that can be computed _up to_ and _from_ the calibration date:\n",
    "- cumulative deaths delta: difference between the total number of fatalities predicted by the model and the (smoothed) total number of fatalities reported\n",
    "- average difference to daily deaths: the mean relative difference between daily predicted and reported values (with some leeway of +/- 10 to prevent small values from having too big of an impact)\n",
    "\n",
    "It is also interesting to look at the score for each model _up to_ the calibration, to see which one appeared more promising _then_.\n",
    "\n",
    "Note: the score _from_ the calibration date can be useful too but is slightly less straightforward to interpret since the normalisation procedure makes uses of earlier data but any penalty incurred then isn't included. This would for instance be useful to calibrate specific intervention periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(df, t_min=None, t_max=None, idm=True, mc19=False, resolution=10, scorer=None):\n",
    "    col_truth = 'deathIncrease'\n",
    "    col_ref = 'deathIncrease_smoothed'\n",
    "    cols = [col_truth,'imperial_incDeath-0.5_smoothed']\n",
    "    if idm:\n",
    "        cols.append('covasim_new_deaths-mean-0.5_smoothed')\n",
    "    if mc19:\n",
    "        cols.append('mc19_dailyDeath-percentile50') \n",
    "    out = {col: {} for col in cols}\n",
    "    \n",
    "    # compute diff dataframe\n",
    "    idx = df.index[~df[col_ref].isnull()]\n",
    "    df_diff = df.loc[idx, [col_ref] + cols].copy()\n",
    "    for col in cols:\n",
    "        # compute distance to col_ref given resolution\n",
    "        delta = df_diff[col].values - df_diff[col_ref].values\n",
    "        \n",
    "        # if within resolutsion: perfect\n",
    "        delta = np.where(np.abs(delta) <= resolution, 0, delta)\n",
    "        \n",
    "        # if prediction above, substract the resolution\n",
    "        delta = np.where(delta > 0 , delta - resolution, delta)\n",
    "        \n",
    "        # if prediction below, add the resolution\n",
    "        delta = np.where(delta < 0 , delta + resolution, delta)\n",
    "\n",
    "        # compute corresponding % (+1 to make sure we don't divide by 0)\n",
    "        df_diff[col + '_delta_pc'] = delta /( df_diff[col_ref] + 1) * 100\n",
    "    out['df'] = df_diff\n",
    "    \n",
    "    # compute duration of specified period\n",
    "    idx = df_diff.index\n",
    "    if t_min is None:\n",
    "        t_min = idx[0]\n",
    "    if t_max is None:\n",
    "        t_max = idx[-1]\n",
    "    idx = df_diff.loc[t_min:t_max].index\n",
    "    out['duration'] = str(pd.Timedelta(idx.values[-1] - idx.values[0]).days)\n",
    "\n",
    "    # compute score\n",
    "    if scorer is not None:\n",
    "        # we \n",
    "        for col in cols:\n",
    "            out[col]['score'] = scorer.score_df(df_diff, col_truth, col, t_min=t_min, t_max=t_max)['score']\n",
    "    \n",
    "    # compute delta cumulative value\n",
    "    out['cumsum_ref'] = df_diff.loc[idx, col_ref].cumsum().values[-1]\n",
    "    for col in cols:\n",
    "        out[col]['cumsum_delta'] = df_diff.loc[idx, col].cumsum().values[-1] - out['cumsum_ref']\n",
    "        out[col]['cumsum_delta_pc'] = round(out[col]['cumsum_delta'] / out['cumsum_ref'] * 100, 2)\n",
    "\n",
    "    # compute relative % to truth\n",
    "    for col in cols:\n",
    "        out[col]['mean_abs_pc'] = round(df_diff.loc[idx, col + '_delta_pc'].abs().mean(), 2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compute_metrics(cal, t_min=None, t_max=None, idm=True, mc19=False, verbose=False):\n",
    "    out = {}\n",
    "    for geo in sorted(data_comparison[cal].keys()):\n",
    "        # get the predictions corresponding to the best covidsim model\n",
    "        df = data_comparison[cal][geo][imperial_scores_sorted[cal][geo][0][0]]\n",
    "        out[geo] = compute_metrics(df, t_min=t_min, t_max=t_max, idm=idm, mc19=mc19, scorer=scorers[geo])\n",
    "        \n",
    "        #display results for geo\n",
    "        if verbose:\n",
    "            print(geo)\n",
    "            print('  duration: ' + str(out[geo]['duration']) + ' days')\n",
    "            for col in out[geo].keys():\n",
    "                if col not in ['duration','df','cumsum_ref']:\n",
    "                    print('  ' + col + ':')\n",
    "                    print('     ', out[geo][col], '')\n",
    "            print('')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models calibrated with data up to `2020-04-30`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal = '2020-04-30'\n",
    "models_metrics[cal] = {}\n",
    "models_metrics[cal]['before'] = batch_compute_metrics(cal=cal, t_max=cal, mc19=False)\n",
    "models_metrics[cal]['after'] = batch_compute_metrics(cal=cal, t_min=cal, t_max='2020-06-15', mc19=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models calibrated with data up to `2020-05-30` (we include `mc19` even though it actually benefited from slightly more recent data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cal = '2020-05-30'\n",
    "models_metrics[cal] = {}\n",
    "models_metrics[cal]['before'] = batch_compute_metrics(cal=cal, t_max=cal, mc19=True)\n",
    "models_metrics[cal]['after'] = batch_compute_metrics(cal=cal, t_min=cal, t_max='2020-06-15', mc19=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can make sure that the loss up to calibration for `covidsim` is the same as the one computed earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = '2020-04-30'\n",
    "geo = 'New_York'\n",
    "print(models_metrics[cal]['before'][geo]['imperial_incDeath-0.5_smoothed']['score'])\n",
    "print(imperial_scores_sorted[cal][geo][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show predictions and summary statistics for each model for each geography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comparison_and_stats(cal, geo, idm=True, mc19=False, t_min='2020-03', t_max=None, t_boundary=None,\n",
    "                              imperial_id=None, figsize=(19,5), axes=None, width_ratios=[1, 1.25], **kwargs):    \n",
    "    col_names = {'imperial_incDeath-0.5_smoothed': 'Imperial',\n",
    "                 'covasim_new_deaths-mean-0.5_smoothed': 'IDM',\n",
    "                 'mc19_dailyDeath-percentile50': 'MC-19'}\n",
    "    col_colours = {'imperial_incDeath-0.5_smoothed':'r',\n",
    "                   'covasim_new_deaths-mean-0.5_smoothed': '#942192',\n",
    "                   'mc19_dailyDeath-percentile50': 'g',\n",
    "                   'deathIncrease_smoothed': '#797979'}    \n",
    "    table_col_colours = {'imperial_incDeath-0.5_smoothed': '#FFD1D4',\n",
    "                         'covasim_new_deaths-mean-0.5_smoothed': '#D0D0FF',\n",
    "                         'mc19_dailyDeath-percentile50': '#D5F4CF',\n",
    "                         'deathIncrease_smoothed': '#797979'}\n",
    "    labels = {'imperial_incDeath-0.5_smoothed': 'Imperial (covidsim)',\n",
    "              'covasim_new_deaths-mean-0.5_smoothed': 'IDM (covasim)',\n",
    "              'mc19_dailyDeath-percentile50': 'Stanford (MC-19)',\n",
    "              'deathIncrease_smoothed': 'reported smoothed',\n",
    "              'deathIncrease': 'reported'}    \n",
    "    if t_boundary is None:\n",
    "        t_boundary = cal\n",
    "    \n",
    "    if axes is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        gs = gridspec.GridSpec(2,2, width_ratios=width_ratios)\n",
    "        axes = [plt.subplot(gs[:,0]), plt.subplot(gs[0,1]), plt.subplot(gs[1,1])]\n",
    "    else:\n",
    "        fig = None\n",
    "    \n",
    "    # graph\n",
    "    #------\n",
    "    if imperial_id is None:\n",
    "        _id = imperial_scores_sorted[cal][geo][0][0]\n",
    "    df = data_comparison[cal][geo][_id]\n",
    "    lines = show_comparison_imperial(df=df,\n",
    "                                 idm=idm,\n",
    "                                 mc19=mc19,\n",
    "                                 t_min=t_min,\n",
    "                                 t_max=t_max,\n",
    "                                 colors={'fill_between': ['r','#B4A9FF','#8AC277'],\n",
    "                                         'cols': col_colours,\n",
    "                                         'scatter': {'deathIncrease': '#797979'}},\n",
    "                                 ax=axes[0],\n",
    "                                 title=geo,\n",
    "                                 title_font={'fontsize': 16, 'fontweight': 'normal'},\n",
    "                                 show_leg=labels,\n",
    "                                 linewidths={cal: 3},\n",
    "                                 show_times=interventions[geo] + [cal],\n",
    "                                 **kwargs)\n",
    "    \n",
    "    # statistics\n",
    "    #-----------\n",
    "    cols = ['deathIncrease','imperial_incDeath-0.5_smoothed']\n",
    "    if idm:\n",
    "        cols.append('covasim_new_deaths-mean-0.5_smoothed')\n",
    "    if mc19:\n",
    "        cols.append('mc19_dailyDeath-percentile50') \n",
    "\n",
    "    # table before\n",
    "    metrics = compute_metrics(df, t_min=t_min, t_max=t_boundary, idm=idm, mc19=mc19, scorer=scorers[geo])\n",
    "    row_1=['cumulative deaths delta (truth=' + str(int(metrics['cumsum_ref'])) + ')']\n",
    "    row_2=['average difference to daily deaths']\n",
    "    row_3=['scoring loss']\n",
    "    colLabels=['UP TO calibration date']\n",
    "    colColours=['#F2F2F2']\n",
    "    for col in cols[1:]:\n",
    "        row_1.append('{:+.2f}'.format(metrics[col]['cumsum_delta_pc']) + '% (' + '{:+d}'.format(int(metrics[col]['cumsum_delta'])) +')')\n",
    "        row_2.append(str(metrics[col]['mean_abs_pc']) + '%')\n",
    "        row_3.append(str(round(metrics[col]['score'],4)))\n",
    "        colLabels.append(col_names[col])\n",
    "        colColours.append(table_col_colours[col])\n",
    "    axes[1].axis('off')\n",
    "    table1 = axes[1].table(cellText=[row_1, row_2, row_3],\n",
    "                           rowLabels=['','',''],\n",
    "                           colLabels=colLabels,\n",
    "                           colColours=colColours,\n",
    "                           bbox=[0, 0, 1, 1],\n",
    "                           colWidths=[0.8] + [0.35]*len(cols))\n",
    "    table1.auto_set_font_size(False)\n",
    "    table1.set_fontsize(12)\n",
    "\n",
    "    # table after\n",
    "    metrics = compute_metrics(df, t_min=t_boundary, t_max=t_max, idm=idm, mc19=mc19, scorer=None)\n",
    "    row_1=['cumulative deaths delta (truth=' + str(int(metrics['cumsum_ref'])) + ')']\n",
    "    row_2=['average difference to daily deaths']\n",
    "    colLabels=['FROM calibration date']\n",
    "    colColours=['#DBDBDB']\n",
    "    for col in cols[1:]:\n",
    "        row_1.append('{:+.2f}'.format(metrics[col]['cumsum_delta_pc']) + '% (' + '{:+d}'.format(int(metrics[col]['cumsum_delta'])) +')')\n",
    "        row_2.append(str(metrics[col]['mean_abs_pc']) + '%')\n",
    "        colLabels.append(col_names[col])\n",
    "        colColours.append(table_col_colours[col])\n",
    "    axes[2].axis('off')\n",
    "    table2 = axes[2].table(cellText=[row_1, row_2],\n",
    "                           rowLabels=['',''],\n",
    "                           colLabels=colLabels,\n",
    "                           colColours=colColours,\n",
    "                           bbox=[0, 0, 1, 1],\n",
    "                           colWidths=[0.8] + [0.35]*len(cols))\n",
    "    table2.auto_set_font_size(False)\n",
    "    table2.set_fontsize(12)\n",
    "\n",
    "    if fig is not None:\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_show_comparison_and_stats(cal, width_ratios=[1, 1.25], figsize=(19,30), **kwargs):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = gridspec.GridSpec(2*len(data_comparison[cal].keys()),2, width_ratios=width_ratios)\n",
    "    for i, geo in enumerate(sorted(data_comparison[cal].keys())):\n",
    "        axes = [plt.subplot(gs[2*i:2*(i+1),0]), plt.subplot(gs[2*i,1]), plt.subplot(gs[2*i+1,1])]\n",
    "        # manual adjustment to scale in NJ to minimise impact due a mistake in the reported data\n",
    "        y_max = 500 if geo == 'New_Jersey' else None\n",
    "        show_comparison_and_stats(cal, geo, axes=axes, y_max=y_max, **kwargs)\n",
    "    gs.tight_layout(fig, rect=[0, 0.03, 1, 0.97])\n",
    "    fig.suptitle(cal, fontsize=22)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the commands below with `t_max='2020-07-13'` should produce figures very similar to those in [./figs/2020-04-30_summary.png](./figs/2020-04-30_summary.png) and [./figs/2020-05-30_summary.png](./figs/2020-05-30_summary.png) (there maybe be small discrepancies due slightly different reported data values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_show_comparison_and_stats('2020-04-30', width_ratios=[1.1, 1], hide_fb=True, t_max='2020-07-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_show_comparison_and_stats('2020-05-30', width_ratios=[1, 1.2], mc19=True, hide_fb=True, t_max='2020-07-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
